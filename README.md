# Big-Data-Analytics-of-US-Accidents

Contains the Project report along with code for Data Cleaning and Exploratory Data Analysis, Modeling and Inference. It includes notebooks for One hot encoding and over and under sampling. 
### Dataset
The dataset is car accidents data for USA with data collected from Feb 2016 to December 2019. The dataset is taken from Kaggle (US car Accidents Feb16 Dec19). It has 2.9 million observations and 49 attributes with both numerical and categorical data. The dataset is for 49 contiguous US states collected through multiple API including 2 APIs which stream real time traffic data. The features can be categorized into geographical features, weather, date-time, POI (point of interest) annotation.

dataset link : https://www.kaggle.com/sobhanmoosavi/us-accidents

### Proposed techniques and Data Science methodology
The methodology planned to be followed to solve the problem consists of different stages. The stages include Business Understanding, Data Preprocessing, Exploratory Data Analysis, Feature Engineering, Data Modeling, Model Evaluation, Recommendations and Insights. Business understanding and data preprocessing tasks comprise of data cleaning, imputation of null values using mean/median, transforming data into meaningful variables or combination of variables. Feature engineering to select the most important features in the dataset. Data modeling includes splitting data into train and validation, running different algorithms such as Decision Tree, Random Forest, Gradient Boost and tuning hyperparameters to build best model. Model evaluation using different metrics such as accuracy, precision, recall, F1 score, AUC/ROC curve to select the best model. Recommendations and insights derived from exploratory analysis and models built to be implemented to solve business problems.
